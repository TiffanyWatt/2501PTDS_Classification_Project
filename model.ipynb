{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72efd882",
   "metadata": {},
   "source": [
    "## ðŸ§° Importing Libraries and Preparing NLTK Resources\n",
    "\n",
    "This section loads the core Python libraries used for data handling, feature extraction, and model training, as well as the NLTK resources required for text preprocessing.\n",
    "\n",
    "### **Imports**\n",
    "- **pandas**, **numpy** â€” data manipulation and numerical operations.  \n",
    "- **re** â€” regular expressions for cleaning text.  \n",
    "- **nltk** â€” natural language toolkit for tokenization, stopwords, and lemmatization.  \n",
    "- **scikit-learn** modules:\n",
    "  - `TfidfVectorizer`, `CountVectorizer` â€” convert text into numerical vectors.\n",
    "  - `train_test_split` â€” split data into training and testing sets.\n",
    "  - `LogisticRegression` â€” build the baseline classification model.\n",
    "  - `accuracy_score`, `classification_report`, `confusion_matrix`, `f1_score` â€” evaluate model performance.\n",
    "  - `LabelEncoder` â€” convert text labels into numeric form.\n",
    "\n",
    "### **NLTK Downloads**\n",
    "The following lines ensure that all necessary linguistic datasets are available locally:\n",
    "```python\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1cb512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\twatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\twatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\twatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\twatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\twatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594e40d",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Loading and Inspecting the Dataset\n",
    "\n",
    "In this step, we load both the **training** and **testing** datasets, apply basic cleaning, and preview the first few rows to understand the structure.\n",
    "\n",
    "### **Code Overview**\n",
    "- The datasets are stored in the `Data/processed` folder as CSV files:\n",
    "  ```python\n",
    "  train = pd.read_csv(\"Data/processed/train.csv\")\n",
    "  test = pd.read_csv(\"Data/processed/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2463721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBI revises definition of politically-exposed ...</td>\n",
       "      <td>The central bank has also asked chairpersons a...</td>\n",
       "      <td>The Reserve Bank of India (RBI) has changed th...</td>\n",
       "      <td>https://indianexpress.com/article/business/ban...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...</td>\n",
       "      <td>NDTV's consolidated revenue from operations wa...</td>\n",
       "      <td>Broadcaster New Delhi Television Ltd on Monday...</td>\n",
       "      <td>https://indianexpress.com/article/business/com...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akasa Air â€˜well capitalisedâ€™, can grow much fa...</td>\n",
       "      <td>The initial share sale will be open for public...</td>\n",
       "      <td>Homegrown server maker Netweb Technologies Ind...</td>\n",
       "      <td>https://indianexpress.com/article/business/mar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indiaâ€™s current account deficit declines sharp...</td>\n",
       "      <td>The current account deficit (CAD) was 3.8 per ...</td>\n",
       "      <td>Indiaâ€™s current account deficit declined sharp...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>States borrowing cost soars to 7.68%, highest ...</td>\n",
       "      <td>The prices shot up reflecting the overall high...</td>\n",
       "      <td>States have been forced to pay through their n...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  RBI revises definition of politically-exposed ...   \n",
       "1  NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...   \n",
       "2  Akasa Air â€˜well capitalisedâ€™, can grow much fa...   \n",
       "3  Indiaâ€™s current account deficit declines sharp...   \n",
       "4  States borrowing cost soars to 7.68%, highest ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The central bank has also asked chairpersons a...   \n",
       "1  NDTV's consolidated revenue from operations wa...   \n",
       "2  The initial share sale will be open for public...   \n",
       "3  The current account deficit (CAD) was 3.8 per ...   \n",
       "4  The prices shot up reflecting the overall high...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The Reserve Bank of India (RBI) has changed th...   \n",
       "1  Broadcaster New Delhi Television Ltd on Monday...   \n",
       "2  Homegrown server maker Netweb Technologies Ind...   \n",
       "3  Indiaâ€™s current account deficit declined sharp...   \n",
       "4  States have been forced to pay through their n...   \n",
       "\n",
       "                                                 url  category  \n",
       "0  https://indianexpress.com/article/business/ban...  business  \n",
       "1  https://indianexpress.com/article/business/com...  business  \n",
       "2  https://indianexpress.com/article/business/mar...  business  \n",
       "3  https://indianexpress.com/article/business/eco...  business  \n",
       "4  https://indianexpress.com/article/business/eco...  business  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLC India wins contract for power supply to Ra...</td>\n",
       "      <td>State-owned firm NLC India Ltd (NLCIL) on Mond...</td>\n",
       "      <td>State-owned firm NLC India Ltd (NLCIL) on Mond...</td>\n",
       "      <td>https://indianexpress.com/article/business/com...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBI Clerk prelims exams dates announced; admit...</td>\n",
       "      <td>SBI Clerk Prelims Exam: The SBI Clerk prelims ...</td>\n",
       "      <td>SBI Clerk Prelims Exam: The State Bank of Indi...</td>\n",
       "      <td>https://indianexpress.com/article/education/sb...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golden Globes: Michelle Yeoh, Will Ferrell, An...</td>\n",
       "      <td>Barbie is the top nominee this year, followed ...</td>\n",
       "      <td>Michelle Yeoh, Will Ferrell, Angela Bassett an...</td>\n",
       "      <td>https://indianexpress.com/article/entertainmen...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnePlus Nord 3 at Rs 27,999 as part of new pri...</td>\n",
       "      <td>New deal makes the OnePlus Nord 3 an easy purc...</td>\n",
       "      <td>In our review of the OnePlus Nord 3 5G, we pra...</td>\n",
       "      <td>https://indianexpress.com/article/technology/t...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adani familyâ€™s partners used â€˜opaqueâ€™ funds to...</td>\n",
       "      <td>Citing review of files from multiple tax haven...</td>\n",
       "      <td>Millions of dollars were invested in some publ...</td>\n",
       "      <td>https://indianexpress.com/article/business/ada...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  NLC India wins contract for power supply to Ra...   \n",
       "1  SBI Clerk prelims exams dates announced; admit...   \n",
       "2  Golden Globes: Michelle Yeoh, Will Ferrell, An...   \n",
       "3  OnePlus Nord 3 at Rs 27,999 as part of new pri...   \n",
       "4  Adani familyâ€™s partners used â€˜opaqueâ€™ funds to...   \n",
       "\n",
       "                                         description  \\\n",
       "0  State-owned firm NLC India Ltd (NLCIL) on Mond...   \n",
       "1  SBI Clerk Prelims Exam: The SBI Clerk prelims ...   \n",
       "2  Barbie is the top nominee this year, followed ...   \n",
       "3  New deal makes the OnePlus Nord 3 an easy purc...   \n",
       "4  Citing review of files from multiple tax haven...   \n",
       "\n",
       "                                             content  \\\n",
       "0  State-owned firm NLC India Ltd (NLCIL) on Mond...   \n",
       "1  SBI Clerk Prelims Exam: The State Bank of Indi...   \n",
       "2  Michelle Yeoh, Will Ferrell, Angela Bassett an...   \n",
       "3  In our review of the OnePlus Nord 3 5G, we pra...   \n",
       "4  Millions of dollars were invested in some publ...   \n",
       "\n",
       "                                                 url       category  \n",
       "0  https://indianexpress.com/article/business/com...       business  \n",
       "1  https://indianexpress.com/article/education/sb...      education  \n",
       "2  https://indianexpress.com/article/entertainmen...  entertainment  \n",
       "3  https://indianexpress.com/article/technology/t...     technology  \n",
       "4  https://indianexpress.com/article/business/ada...       business  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Data/processed/train.csv\")\n",
    "test = pd.read_csv(\"Data/processed/test.csv\")\n",
    "\n",
    "# Applying our post inspection changes\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "display(train.head(), test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc69085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBI revises definition of politically-exposed ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akasa Air â€˜well capitalisedâ€™, can grow much fa...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indiaâ€™s current account deficit declines sharp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>States borrowing cost soars to 7.68%, highest ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  category\n",
       "0  RBI revises definition of politically-exposed ...  business\n",
       "1  NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...  business\n",
       "2  Akasa Air â€˜well capitalisedâ€™, can grow much fa...  business\n",
       "3  Indiaâ€™s current account deficit declines sharp...  business\n",
       "4  States borrowing cost soars to 7.68%, highest ...  business"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLC India wins contract for power supply to Ra...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBI Clerk prelims exams dates announced; admit...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golden Globes: Michelle Yeoh, Will Ferrell, An...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnePlus Nord 3 at Rs 27,999 as part of new pri...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adani familyâ€™s partners used â€˜opaqueâ€™ funds to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data       category\n",
       "0  NLC India wins contract for power supply to Ra...       business\n",
       "1  SBI Clerk prelims exams dates announced; admit...      education\n",
       "2  Golden Globes: Michelle Yeoh, Will Ferrell, An...  entertainment\n",
       "3  OnePlus Nord 3 at Rs 27,999 as part of new pri...     technology\n",
       "4  Adani familyâ€™s partners used â€˜opaqueâ€™ funds to...       business"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['data'] = train['headlines'] + ' ' + train['content']\n",
    "test['data'] = test['headlines'] + ' ' + test['content']\n",
    "\n",
    "train = train[['data', 'category']]\n",
    "test = test[['data', 'category']]\n",
    "\n",
    "display(train.head(), test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e58840",
   "metadata": {},
   "source": [
    "## ðŸ§¼ Refined Text Cleaning and Preprocessing\n",
    "\n",
    "This function standardizes and cleans each news article before itâ€™s fed into the model.  \n",
    "It expands on the model version by adding contraction handling, smarter regex cleanup, and improved token filtering.\n",
    "\n",
    "### ðŸ§  Why These Steps Matter\n",
    "\n",
    "- **Removes noise** such as URLs, hashtags, and symbols that donâ€™t add meaning.  \n",
    "- **Handles contractions** (â€œdonâ€™tâ€ â†’ â€œdo notâ€) to retain grammatical intent.  \n",
    "- **Keeps digits** since numbers can be meaningful in financial or tech news.  \n",
    "- **Preserves negations** like â€œnot_goodâ€ to help the model understand sentiment and tone.  \n",
    "- **Lemmatizes tokens** to reduce variations of the same word (e.g., â€œrunsâ€, â€œrunningâ€ â†’ â€œrunâ€).  \n",
    "- **Filters stopwords and normalizes spaces** for a cleaner, standardized text dataset.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Why This Is an Improvement\n",
    "\n",
    "Compared to earlier preprocessing versions, this refined approach:\n",
    "\n",
    "- **Expands contractions**, improving text clarity and readability.  \n",
    "- **Retains numerals** that often carry value in business, tech, and quantitative news.  \n",
    "- **Uses compiled regex patterns** for faster, more efficient text cleaning.  \n",
    "- **Produces more consistent and lower-noise text**, giving the TF-IDF vectorizer higher-quality input.  \n",
    "\n",
    "Overall, this version ensures the model learns from **meaningful, normalized language patterns**, which enhances both **accuracy** and **generalization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6daa482",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_urls = re.compile(r\"http\\S+|www\\S+|@\\w+|#\\w+\")\n",
    "keep_alnum = re.compile(r\"[^a-z0-9\\s]\")\n",
    "spaces = re.compile(r\"\\s+\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_text_pro(text: str) -> str:\n",
    "    t = text.lower()\n",
    "    t = clean_urls.sub(\" \", t)\n",
    "    # normalize simple contractions\n",
    "    t = re.sub(r\"n['â€™]t\\b\", \" not\", t)\n",
    "    t = re.sub(r\"['â€™]re\\b\", \" are\", t)\n",
    "    t = re.sub(r\"['â€™]ve\\b\", \" have\", t)\n",
    "    # keep digits; strip other symbols\n",
    "    t = keep_alnum.sub(\" \", t)\n",
    "    # bind simple negations\n",
    "    t = re.sub(r\"\\b(not|no|never)\\s+(\\w+)\", r\"\\1_\\2\", t)\n",
    "    t = spaces.sub(\" \", t).strip()\n",
    "\n",
    "    toks = word_tokenize(t)\n",
    "    toks = [w for w in toks if w not in stop_words and len(w) > 1]\n",
    "    toks = [lemmatizer.lemmatize(w) for w in toks]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "# apply\n",
    "train['data'] = train['data'].apply(process_text_pro)\n",
    "test['data']  = test['data'].apply(process_text_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a855a",
   "metadata": {},
   "source": [
    "## ðŸ”  TF-IDF Vectorization and Logistic Regression Training\n",
    "\n",
    "This section converts the cleaned text data into numerical form using **TF-IDF** (Term Frequencyâ€“Inverse Document Frequency) and trains a **Logistic Regression** model to classify news articles by category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc52e35",
   "metadata": {},
   "source": [
    "## ðŸ”  TF-IDF Vectorization and Logistic Regression Training\n",
    "\n",
    "This section converts the cleaned text data into numerical form using **TF-IDF** (Term Frequencyâ€“Inverse Document Frequency) and trains a **Logistic Regression** model to classify news articles by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8b2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (5520, 5000)\n",
      "Vocabulary: ['aadhaar' 'aamir' 'aamir khan' ... 'zoom' 'zoya' 'zoya akhtar']\n",
      "Training Accuracy: 0.99\n",
      "Validation Accuracy: 0.98\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.96      0.97       400\n",
      "    education       1.00      0.99      0.99       400\n",
      "entertainment       1.00      0.99      0.99       400\n",
      "   technology       0.99      0.98      0.99       400\n",
      "       sports       0.94      0.98      0.96       400\n",
      "\n",
      "     accuracy                           0.98      2000\n",
      "    macro avg       0.98      0.98      0.98      2000\n",
      " weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train['data']\n",
    "y_train = train['category']\n",
    "\n",
    "X_test = test['data']\n",
    "y_test = test['category']\n",
    "\n",
    "\n",
    "# Initialise TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Unigrams and bigrams; adjust max_features as needed\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "Xt_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Display the shape of the resulting sparse matrix\n",
    "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")\n",
    "\n",
    "# Display the vocabulary (optional)\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_tfidf, y_train)\n",
    "\n",
    "# Print training accuracy\n",
    "train_accuracy = model.score(X_tfidf, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(Xt_tfidf)\n",
    "\n",
    "# Compute validation accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Validation Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=y_test.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adca685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right')\n",
    "    plt.yticks(ticks, classes)\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "labels = sorted(y.unique())\n",
    "cm = confusion_matrix(y_val, best.predict(X_val), labels=labels)\n",
    "plot_confusion_matrix(cm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1afd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d144fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickled_files/model_and_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': model, 'vectorizer': tfidf_vectorizer}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff33aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input(\"Today is the day that we make business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf95ab36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt= process_text_pro(input_text)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9ddf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_t = tfidf_vectorizer.transform([pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d359ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 0 stored elements and shape (1, 5000)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e47e84ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vect_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cd7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technology']\n",
      "['technology']\n",
      "['technology']\n",
      "['technology']\n",
      "['technology']\n"
     ]
    }
   ],
   "source": [
    "breaker = True\n",
    "\n",
    "while breaker:\n",
    "    input_text = input(\"Enter Text to Classify, Enter End/Quit to end program\")\n",
    "\n",
    "    if input_text.lower() == \"end\" or input_text.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        pt = process_text_pro(input_text)\n",
    "        vect_t = tfidf_vectorizer.transform([pt])\n",
    "        p_class = model.predict(vect_t)\n",
    "        print(p_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b4714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
